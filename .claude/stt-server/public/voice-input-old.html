<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>PAI Live Voice Input</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      color: #fff;
    }

    .container {
      background: rgba(255, 255, 255, 0.1);
      backdrop-filter: blur(10px);
      border-radius: 20px;
      padding: 40px;
      max-width: 600px;
      width: 90%;
      box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
    }

    h1 {
      text-align: center;
      margin-bottom: 10px;
      font-size: 32px;
    }

    .subtitle {
      text-align: center;
      opacity: 0.8;
      margin-bottom: 30px;
    }

    .status {
      text-align: center;
      padding: 15px;
      border-radius: 10px;
      margin-bottom: 20px;
      background: rgba(255, 255, 255, 0.1);
    }

    .status.connected {
      background: rgba(76, 175, 80, 0.3);
    }

    .status.recording {
      background: rgba(244, 67, 54, 0.3);
      animation: pulse 1.5s ease-in-out infinite;
    }

    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.7; }
    }

    .mic-button {
      width: 120px;
      height: 120px;
      border-radius: 50%;
      border: none;
      background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
      color: white;
      font-size: 48px;
      cursor: pointer;
      margin: 20px auto;
      display: block;
      transition: transform 0.2s, box-shadow 0.2s;
      box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
    }

    .mic-button:hover {
      transform: scale(1.05);
      box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
    }

    .mic-button:active {
      transform: scale(0.95);
    }

    .mic-button.recording {
      background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);
      animation: recording-pulse 1s ease-in-out infinite;
    }

    @keyframes recording-pulse {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.1); }
    }

    .transcript-container {
      background: rgba(0, 0, 0, 0.2);
      border-radius: 10px;
      padding: 20px;
      min-height: 150px;
      max-height: 300px;
      overflow-y: auto;
      margin-top: 20px;
    }

    .transcript {
      line-height: 1.6;
      word-wrap: break-word;
    }

    .interim {
      opacity: 0.6;
      font-style: italic;
    }

    .final {
      opacity: 1;
    }

    .controls {
      display: flex;
      gap: 10px;
      margin-top: 20px;
      justify-content: center;
    }

    button {
      padding: 10px 20px;
      border: none;
      border-radius: 8px;
      background: rgba(255, 255, 255, 0.2);
      color: white;
      cursor: pointer;
      transition: background 0.2s;
    }

    button:hover {
      background: rgba(255, 255, 255, 0.3);
    }

    .stats {
      display: flex;
      justify-content: space-around;
      margin-top: 20px;
      padding: 15px;
      background: rgba(0, 0, 0, 0.2);
      border-radius: 10px;
      font-size: 14px;
    }

    .stat-item {
      text-align: center;
    }

    .stat-value {
      font-size: 24px;
      font-weight: bold;
      display: block;
    }

    .stat-label {
      opacity: 0.7;
      font-size: 12px;
    }

    .error {
      background: rgba(244, 67, 54, 0.3);
      padding: 15px;
      border-radius: 10px;
      margin-top: 20px;
      text-align: center;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>üéôÔ∏è PAI Live Voice Input</h1>
    <p class="subtitle">Speak into your microphone to transcribe in real-time</p>

    <div class="status" id="status">
      <span id="status-text">üîå Connecting to server...</span>
    </div>

    <button class="mic-button" id="mic-button" title="Click to start/stop recording">
      üé§
    </button>

    <div class="transcript-container">
      <div class="transcript" id="transcript">
        <span style="opacity: 0.5;">Your transcript will appear here...</span>
      </div>
    </div>

    <div class="controls">
      <button id="clear-btn">Clear Transcript</button>
      <button id="copy-btn">Copy to Clipboard</button>
    </div>

    <div class="stats">
      <div class="stat-item">
        <span class="stat-value" id="duration">0.0s</span>
        <span class="stat-label">Duration</span>
      </div>
      <div class="stat-item">
        <span class="stat-value" id="cost">$0.00</span>
        <span class="stat-label">Est. Cost</span>
      </div>
      <div class="stat-item">
        <span class="stat-value" id="words">0</span>
        <span class="stat-label">Words</span>
      </div>
    </div>
  </div>

  <script>
    const WS_URL = 'ws://localhost:8889/transcribe/stream';
    const COST_PER_MINUTE = 0.0077; // Deepgram Nova-3

    let ws = null;
    let mediaRecorder = null;
    let audioContext = null;
    let isRecording = false;
    let startTime = null;
    let fullTranscript = "";
    let wordCount = 0;

    // DOM elements
    const statusEl = document.getElementById('status');
    const statusTextEl = document.getElementById('status-text');
    const micButton = document.getElementById('mic-button');
    const transcriptEl = document.getElementById('transcript');
    const durationEl = document.getElementById('duration');
    const costEl = document.getElementById('cost');
    const wordsEl = document.getElementById('words');
    const clearBtn = document.getElementById('clear-btn');
    const copyBtn = document.getElementById('copy-btn');

    // Initialize WebSocket connection
    function connectWebSocket() {
      ws = new WebSocket(WS_URL);

      ws.onopen = () => {
        console.log('‚úÖ WebSocket connected');
        statusTextEl.textContent = '‚úÖ Connected - Click microphone to start';
        statusEl.className = 'status connected';
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);

        if (data.type === 'transcript') {
          const text = data.transcript;
          const isFinal = data.is_final;

          if (isFinal) {
            fullTranscript += text + ' ';
            updateTranscript(fullTranscript);
            countWords();
          } else {
            updateTranscript(fullTranscript + `<span class="interim">${text}</span>`);
          }
        } else if (data.type === 'error') {
          console.error('‚ùå Server error:', data.message);
          showError(data.message);
        }
      };

      ws.onerror = (error) => {
        console.error('‚ùå WebSocket error:', error);
        statusTextEl.textContent = '‚ùå Connection error';
        statusEl.className = 'status';
      };

      ws.onclose = () => {
        console.log('üîå WebSocket closed');
        statusTextEl.textContent = 'üîå Disconnected';
        statusEl.className = 'status';
        if (isRecording) {
          stopRecording();
        }
      };
    }

    // Start recording
    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // Create audio context for processing
        audioContext = new AudioContext({ sampleRate: 16000 });
        const source = audioContext.createMediaStreamSource(stream);
        const processor = audioContext.createScriptProcessor(4096, 1, 1);

        source.connect(processor);
        processor.connect(audioContext.destination);

        processor.onaudioprocess = (e) => {
          if (!isRecording || !ws || ws.readyState !== WebSocket.OPEN) return;

          const inputData = e.inputBuffer.getChannelData(0);
          const pcmData = convertFloat32ToInt16(inputData);
          ws.send(pcmData);
        };

        isRecording = true;
        startTime = Date.now();
        micButton.classList.add('recording');
        statusTextEl.textContent = 'üéôÔ∏è Recording... (speak now)';
        statusEl.className = 'status recording';

        updateStats();

      } catch (error) {
        console.error('‚ùå Microphone access denied:', error);
        showError('Microphone access denied. Please allow microphone access and try again.');
      }
    }

    // Stop recording
    function stopRecording() {
      isRecording = false;
      if (audioContext) {
        audioContext.close();
        audioContext = null;
      }
      micButton.classList.remove('recording');
      statusTextEl.textContent = '‚úÖ Connected - Click microphone to start';
      statusEl.className = 'status connected';
    }

    // Convert Float32Array to Int16Array (PCM)
    function convertFloat32ToInt16(buffer) {
      const l = buffer.length;
      const buf = new Int16Array(l);
      for (let i = 0; i < l; i++) {
        buf[i] = Math.min(1, buffer[i]) * 0x7FFF;
      }
      return buf.buffer;
    }

    // Update transcript display
    function updateTranscript(html) {
      transcriptEl.innerHTML = html || '<span style="opacity: 0.5;">Your transcript will appear here...</span>';
      transcriptEl.scrollTop = transcriptEl.scrollHeight;
    }

    // Count words
    function countWords() {
      wordCount = fullTranscript.trim().split(/\s+/).filter(w => w.length > 0).length;
      wordsEl.textContent = wordCount;
    }

    // Update stats
    function updateStats() {
      if (!isRecording) return;

      const elapsed = (Date.now() - startTime) / 1000;
      const minutes = elapsed / 60;
      const cost = minutes * COST_PER_MINUTE;

      durationEl.textContent = elapsed.toFixed(1) + 's';
      costEl.textContent = '$' + cost.toFixed(4);

      requestAnimationFrame(updateStats);
    }

    // Show error
    function showError(message) {
      const errorDiv = document.createElement('div');
      errorDiv.className = 'error';
      errorDiv.textContent = '‚ùå ' + message;
      document.querySelector('.container').appendChild(errorDiv);
      setTimeout(() => errorDiv.remove(), 5000);
    }

    // Event listeners
    micButton.addEventListener('click', () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    });

    clearBtn.addEventListener('click', () => {
      fullTranscript = "";
      wordCount = 0;
      updateTranscript("");
      wordsEl.textContent = "0";
    });

    copyBtn.addEventListener('click', () => {
      navigator.clipboard.writeText(fullTranscript.trim());
      copyBtn.textContent = '‚úÖ Copied!';
      setTimeout(() => {
        copyBtn.textContent = 'Copy to Clipboard';
      }, 2000);
    });

    // Initialize on page load
    connectWebSocket();

    // Reconnect on disconnect
    setInterval(() => {
      if (!ws || ws.readyState === WebSocket.CLOSED) {
        connectWebSocket();
      }
    }, 5000);
  </script>
</body>
</html>
